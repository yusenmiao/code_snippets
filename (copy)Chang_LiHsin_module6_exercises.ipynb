{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chang_LiHsin_module6_exercises.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yusenmiao/code_snippets/blob/master/(copy)Chang_LiHsin_module6_exercises.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3yIFGXLYzmiN"
      },
      "source": [
        "# Module 6 Exercises"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g4DMG_rJzwZq"
      },
      "source": [
        "## The breast cancer Wisconsin dataset (classification problem)\n",
        "\n",
        "Let us build two predictive models on the following dataset:\n",
        "\n",
        "(http://archive.ics.uci.edu/ml/datasets/breast+cancer+wisconsin+%28original%29)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "exnwFpEaVOxt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e033441-4967-4aab-e79c-562dafd9b54e"
      },
      "source": [
        "# load the breast cancer Wisconsin dataset\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "cancer = load_breast_cancer()\n",
        "type(cancer)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "sklearn.utils.Bunch"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPdHmxPMYyrq"
      },
      "source": [
        "Bunch is a Dictionary-like object in Scikit-Learn. The interesting attributes are: \n",
        "- ‘data’, the data to learn, \n",
        "- ‘target’, the classification labels, \n",
        "-‘target_names’, the meaning of the labels, \n",
        "- ‘feature_names’, the meaning of the features, and \n",
        "-‘DESCR’, the full description of the dataset, \n",
        "- ‘filename’, the physical location of breast cancer csv dataset (added in version 0.20)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_sHliMPZCIq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea67938b-c551-431f-c2cd-fc1cf7cd7f89"
      },
      "source": [
        "list(cancer.feature_names)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['mean radius',\n",
              " 'mean texture',\n",
              " 'mean perimeter',\n",
              " 'mean area',\n",
              " 'mean smoothness',\n",
              " 'mean compactness',\n",
              " 'mean concavity',\n",
              " 'mean concave points',\n",
              " 'mean symmetry',\n",
              " 'mean fractal dimension',\n",
              " 'radius error',\n",
              " 'texture error',\n",
              " 'perimeter error',\n",
              " 'area error',\n",
              " 'smoothness error',\n",
              " 'compactness error',\n",
              " 'concavity error',\n",
              " 'concave points error',\n",
              " 'symmetry error',\n",
              " 'fractal dimension error',\n",
              " 'worst radius',\n",
              " 'worst texture',\n",
              " 'worst perimeter',\n",
              " 'worst area',\n",
              " 'worst smoothness',\n",
              " 'worst compactness',\n",
              " 'worst concavity',\n",
              " 'worst concave points',\n",
              " 'worst symmetry',\n",
              " 'worst fractal dimension']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zjc1NEgrZJ00",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22910505-c567-4e70-eac0-13a2f274394f"
      },
      "source": [
        "list(cancer.target_names)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['malignant', 'benign']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S7_EEqvXeNGU"
      },
      "source": [
        "## Question 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQ6eURzEZNBT"
      },
      "source": [
        "# split the data into training and test data\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target, test_size=0.25, random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YOn3L_1QhUVG"
      },
      "source": [
        "# Let us apply Feature Scaling to our data\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3ITKmLRbKlP"
      },
      "source": [
        "# Use GaussianNB method of Naive Bayes class to build a prediction model on training data\n",
        "# Obtain the accuracy of your model predictions on test data\n",
        "# Create a confusion matrix as part of your output\n",
        "\n",
        "# ANSWER:\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vlJzZd-seRdH"
      },
      "source": [
        "## Question 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fsoLGbAdeR_O"
      },
      "source": [
        "# split the data into training and test data\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target, test_size=0.25, random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Mmue8Z-grYT"
      },
      "source": [
        "# Let us apply Feature Scaling to our data\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BFmnsCIee0Yq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "outputId": "0b2252c4-8423-4285-cec2-f532aa223f0e"
      },
      "source": [
        "# Use Support vector Machines (SVM) class in Scikit-Learn to build a prediction model on training data\n",
        "# Obtain the accuracy of your model predictions on test data\n",
        "# Create a confusion matrix as part of your output\n",
        "\n",
        "# ANSWER:\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-6a86605e63b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# ANSWER:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mmat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False,\n\u001b[1;32m      9\u001b[0m             \u001b[0mxticklabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mconfusion_matrix\u001b[0;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m     \"\"\"\n\u001b[0;32m--> 268\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s is not supported\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \"\"\"\n\u001b[0;32m---> 80\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 212\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [426, 143]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3hwLh1nrgTig"
      },
      "source": [
        "## Question 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9J4KdQtqt1Rw"
      },
      "source": [
        "## Diabetes dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yUScpvSHzZQ3"
      },
      "source": [
        "https://www4.stat.ncsu.edu/~boos/var.select/diabetes.html\n",
        "\n",
        "The dataset contains 10 features (that have already been mean centered and scaled) and a target value: a measure of disease progression one year after baseline."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GiyvZ8Esz5dj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ced50e2-30ee-43fb-e3cb-b1d10a8e1d6d"
      },
      "source": [
        "# load the dataset\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_diabetes\n",
        "X, y = load_diabetes(return_X_y=True)\n",
        "X = pd.DataFrame(X)\n",
        "y = pd.DataFrame(y)\n",
        "print(X.head())\n",
        "print(y.head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "          0         1         2  ...         7         8         9\n",
            "0  0.038076  0.050680  0.061696  ... -0.002592  0.019908 -0.017646\n",
            "1 -0.001882 -0.044642 -0.051474  ... -0.039493 -0.068330 -0.092204\n",
            "2  0.085299  0.050680  0.044451  ... -0.002592  0.002864 -0.025930\n",
            "3 -0.089063 -0.044642 -0.011595  ...  0.034309  0.022692 -0.009362\n",
            "4  0.005383 -0.044642 -0.036385  ... -0.002592 -0.031991 -0.046641\n",
            "\n",
            "[5 rows x 10 columns]\n",
            "       0\n",
            "0  151.0\n",
            "1   75.0\n",
            "2  141.0\n",
            "3  206.0\n",
            "4  135.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKTzoY_Y0xfE"
      },
      "source": [
        "# setting up training set and test set \n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWBs2_fp1Wlp"
      },
      "source": [
        "# fit a linear regression model on training data and determine training set score and test set score\n",
        "# ANSWER:\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHMqKqjt1tJs"
      },
      "source": [
        "# fit a Lasso regresion model with default value for alpha=1\n",
        "# determine training set score and test set score\n",
        "# find optimal alpha with grid search over the following list\n",
        "alpha = [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
        "\n",
        "from sklearn.linear_model import Lasso\n",
        "\n",
        "\n",
        "# ANSWER:\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}